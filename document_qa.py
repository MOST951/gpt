import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS


def render_document_qa():
    """æ¸²æŸ“æ–‡æ¡£é—®ç­”æ¨¡å—"""
    st.header("ğŸ“š æ–‡æ¡£æ™ºèƒ½é—®ç­”")

    # é—®é¢˜è¾“å…¥
    question = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜", key="doc_question")

    if question and st.session_state.get('session_id'):
        with st.spinner('æ­£åœ¨åˆ†ææ–‡æ¡£...'):
            try:
                if st.session_state.is_new_file:
                    loader = TextLoader(f'{st.session_state.session_id}.txt', encoding='utf-8')
                    docs = loader.load()

                    text_splitter = RecursiveCharacterTextSplitter(
                        chunk_size=1000,
                        chunk_overlap=200,
                        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ"]
                    )
                    texts = text_splitter.split_documents(docs)

                    st.session_state.rag_db = FAISS.from_documents(
                        texts,
                        embedding=None  # ä½¿ç”¨é»˜è®¤çš„embedding
                    )
                    st.session_state.is_new_file = False

                model = ChatOpenAI(
                    model=st.session_state.selected_model,
                    api_key=st.secrets['API_KEY'],
                    base_url='https://api.openai.com/v1',
                    temperature=0.2
                )

                qa_chain = ConversationalRetrievalChain.from_llm(
                    llm=model,
                    retriever=st.session_state.rag_db.as_retriever(
                        search_type="mmr",
                        search_kwargs={'k': 3}
                    ),
                    memory=st.session_state.rag_memory,
                    return_source_documents=True
                )

                result = qa_chain({'question': question})

                st.subheader("ç­”æ¡ˆ")
                st.write(result['answer'])

                with st.expander("å‚è€ƒæ–‡æ¡£ç‰‡æ®µ"):
                    for doc in result['source_documents']:
                        st.markdown(f"**æ¥æº**: `{doc.metadata['source']}`")
                        st.text(doc.page_content[:300] + "...")
                        st.divider()

            except Exception as e:
                st.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥ï¼š{str(e)}")