import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory


def get_ai_response(memory, user_prompt, system_prompt="", model_name='gpt-4o-mini',
                    temperature=0.2, top_p=0.1, frequency_penalty=0, max_tokens=512):
    """
    é€šç”¨AIå“åº”ç”Ÿæˆå‡½æ•°

    Args:
        memory: ä¼šè¯è®°å¿†
        user_prompt: ç”¨æˆ·æç¤º
        system_prompt: ç³»ç»Ÿæç¤º
        model_name: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•°
        top_p: ç™¾åˆ†æ¯”æ’åå‚æ•°
        frequency_penalty: é¢‘ç‡æƒ©ç½šåŠ›åº¦
        max_tokens: æœ€å¤§tokenæ•°é‡

    Returns:
        AIå“åº”
    """
    try:
        if not st.session_state.API_KEY:
            return "è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥"

        model = ChatOpenAI(
            model=model_name,
            api_key=st.secrets['API_KEY'],
            base_url='https://api.openai.com/v1',
            temperature=temperature,
            max_tokens=max_tokens
        )
        chain = ConversationChain(llm=model, memory=memory)
        full_prompt = f"System: {system_prompt}\nUser: {user_prompt}"
        response = chain.invoke({'input': full_prompt})['response']
        return response
    except Exception as e:
        st.error(f"AIè¯·æ±‚å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥æˆ–APIå¯†é’¥é…ç½®ã€‚é”™è¯¯ä¿¡æ¯ï¼š{str(e)}")
        return "æ— æ³•ç”Ÿæˆå“åº”ï¼Œè¯·æ£€æŸ¥é…ç½®"


def render_chat():
    """æ¸²æŸ“èŠå¤©æ¨¡å—"""
    st.header("ğŸ’¬ æ™ºèƒ½èŠå¤©")

    # æ˜¾ç¤ºæ¶ˆæ¯å†å²
    for msg in st.session_state.chat_messages:
        role = "user" if msg["role"] == "human" else "assistant"
        with st.chat_message(role):
            st.write(msg["content"])

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        handle_chat_input(prompt)


def handle_chat_input(prompt):
    """
    å¤„ç†èŠå¤©è¾“å…¥

    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„æç¤º
    """
    if not st.session_state.API_KEY:
        st.warning("ğŸ”‘ è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥APIå¯†é’¥")
        return

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.chat_messages.append({'role': 'human', 'content': prompt})

    # è·å–AIå“åº”
    with st.spinner('æ€è€ƒä¸­...'):
        response = get_ai_response(
            memory=st.session_state.chat_memory,
            user_prompt=prompt,
            system_prompt=st.session_state.system_prompt
        )

    # æ·»åŠ AIå“åº”
    st.session_state.chat_messages.append({'role': 'ai', 'content': response})
    st.rerun()